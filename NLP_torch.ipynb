{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPggdjxWRgwU33f5nr4QwAr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omergenkin/Projects/blob/main/NLP_torch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8uNfwM_bgke",
        "outputId": "c3a5ea98-2ad9-42ab-dfa1-5df20e123fee"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "diB7MKlN-bq9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ast import increment_lineno\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "ZTTy-W9z-nqa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zzgq7L-a_dyy",
        "outputId": "c471804b-f92f-463c-b137-54ce9bcfc4fe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/My Drive/pytorch_udemy/Udemy_pytorch/PYTORCH_NOTEBOOKS/Data/shakespeare.txt', 'r') as f:\n",
        "  text = f.read()"
      ],
      "metadata": {
        "id": "BhoM3aqq_q9i"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_characters = set(text)"
      ],
      "metadata": {
        "id": "kZiykAplBMdg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = {char: ind for ind, char in enumerate(all_characters)}\n",
        "decoder = {ind: char for ind, char in enumerate(all_characters)}"
      ],
      "metadata": {
        "id": "UBjEsKl2DNUm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_text = np.array([encoder[char] for char in text])"
      ],
      "metadata": {
        "id": "AuD5qhsaDg1o"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encoder(encoder_text, num_uni_chars):\n",
        "  # encoded_text --> batch of encoded text\n",
        "  # num_uni_char --> len(set(text))\n",
        "  one_hot = np.zeros((encoder_text.size, num_uni_chars))\n",
        "  one_hot = one_hot.astype(np.float32)\n",
        "  one_hot[np.arange(one_hot.shape[0]), encoder_text.flatten()] = 1.0\n",
        "  one_hot = one_hot.reshape((*encoder_text.shape, num_uni_chars))\n",
        "  return one_hot"
      ],
      "metadata": {
        "id": "edYTQYVMEapA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_batches(encoder_text, samp_per_batch=10, seq_len=50):\n",
        "\n",
        "  # X : encoded text of length seq_len\n",
        "  # y : encoded text shifted by one\n",
        "  # how many chars per batch\n",
        "  char_per_batch = samp_per_batch*seq_len\n",
        "\n",
        "  # how many batches can we make, given the len of encoded text\n",
        "  num_batches_avail = int(len(encoder_text)/char_per_batch)\n",
        "  #cut off the end of the encoded text. that won't fit evenly into the batch\n",
        "  encoder_text = encoder_text[:num_batches_avail*char_per_batch]\n",
        "  # reshape into batch_size rows\n",
        "  encoder_text = encoder_text.reshape((samp_per_batch, -1))\n",
        "  #go through each row in array\n",
        "  for n in range(0, encoder_text.shape[1], seq_len):\n",
        "    #grab feature chars\n",
        "    x = encoder_text[:, n:n+seq_len]\n",
        "    #shift label chars by one\n",
        "    y = np.zeros_like(x)\n",
        "    try:\n",
        "      y[:, :-1] = x[:, 1:]\n",
        "      y[:, -1] = encoder_text[:, n+seq_len]\n",
        "    except:\n",
        "      y[:, :-1] = x[:, 1:]\n",
        "      y[:, -1] = -1\n",
        "    yield x, y\n",
        ""
      ],
      "metadata": {
        "id": "qV5ylBZYFz-H"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampel_text = np.arange(20)"
      ],
      "metadata": {
        "id": "ymATppTqL8i1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_generator = generate_batches(sampel_text, samp_per_batch=2, seq_len=5)"
      ],
      "metadata": {
        "id": "En2hr-CJMB8_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x,y = next(batch_generator)"
      ],
      "metadata": {
        "id": "w-sGeNs2MGVR"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "io4ZNQOrMKc_",
        "outputId": "41855343-f9b2-4efa-8778-d6abe48df331"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  1,  2,  3,  4],\n",
              "       [10, 11, 12, 13, 14]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mc04XWkbMLXX",
        "outputId": "d68e6491-b798-4dda-c6b2-e4c7e5c50a58"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1,  2,  3,  4,  5],\n",
              "       [11, 12, 13, 14, 15]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CharModel(nn.Module):\n",
        "\n",
        "  def __init__(self, all_chars,num_hidden=256, num_layers=4, drop_prob=0.5, use_gpu=False):\n",
        "\n",
        "    super().__init__()\n",
        "    self.drop_prob = drop_prob\n",
        "    self.num_layers = num_layers\n",
        "    self.num_hidden = num_hidden\n",
        "    self.use_gpu = use_gpu\n",
        "\n",
        "    self.all_chars = all_chars\n",
        "    self.decoder = decoder\n",
        "    self.encoder = encoder\n",
        "\n",
        "    self.lstm = nn.LSTM(len(self.all_chars), num_hidden, num_layers, dropout=drop_prob, batch_first=True)\n",
        "    self.dropout = nn.Dropout(drop_prob)\n",
        "    self.fc_linear = nn.Linear(num_hidden, len(self.all_chars))\n",
        "\n",
        "  def forward(self, x, hidden):\n",
        "\n",
        "    lstm_output, hidden = self.lstm(x, hidden)\n",
        "    drop_output = self.dropout(lstm_output)\n",
        "    drop_output = drop_output.contiguous().view(-1, self.num_hidden)\n",
        "    final_out = self.fc_linear(drop_output)\n",
        "\n",
        "    return final_out, hidden\n",
        "\n",
        "  def hidden_state(self, batch_size):\n",
        "\n",
        "    if self.use_gpu:\n",
        "      hidden = (torch.zeros(self.num_layers, batch_size, self.num_hidden).cuda(),\n",
        "                torch.zeros(self.num_layers, batch_size, self.num_hidden).cuda())\n",
        "    else:\n",
        "      hidden = (torch.zeros(self.num_layers, batch_size, self.num_hidden),\n",
        "                torch.zeros(self.num_layers, batch_size, self.num_hidden))\n",
        "    return hidden\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "H7KGkaA6MPY3"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CharModel(all_chars=all_characters,\n",
        "                  num_hidden=512,\n",
        "                  num_layers=3,\n",
        "                  drop_prob=0.5,\n",
        "                  use_gpu=True)"
      ],
      "metadata": {
        "id": "YS3lC7sBVaBf"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_param = []\n",
        "\n",
        "for p in model.parameters():\n",
        "  total_param.append(int(p.numel()))\n",
        "sum(total_param)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1f5I_RCVlG3",
        "outputId": "92231f46-3c38-40ef-d90d-2a6e9eee966f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5470292"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "OS-E3sUrVsbt"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_percent = 0.1\n",
        "train_ind = int(len(encoder_text)*(train_percent))\n",
        "train_data = encoder_text[:train_ind]\n",
        "val_data = encoder_text[train_ind:]"
      ],
      "metadata": {
        "id": "hZ7TZyIRV-cd"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_percent = 0.9\n",
        "train_ind = int(len(encoder_text)*(train_percent))\n",
        "train_data = encoder_text[:train_ind]\n",
        "val_data = encoder_text[train_ind:]"
      ],
      "metadata": {
        "id": "f6nPy0vXWDb-"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 12\n",
        "batch_size = 100\n",
        "seq_len = 100\n",
        "tracker = 0\n",
        "num_char = max(encoder.values())+1"
      ],
      "metadata": {
        "id": "kqstPpBQWSYt"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "source": [
        "model.train()\n",
        "if model.use_gpu:\n",
        "  model.cuda()\n",
        "# else:\n",
        "#   model.use_gpu = False\n",
        "\n",
        "for i in range(epochs):\n",
        "  hidden = model.hidden_state(batch_size)\n",
        "  for x,y in generate_batches(train_data, batch_size, seq_len):\n",
        "    tracker += 1\n",
        "    x = one_hot_encoder(x, num_char)\n",
        "    inputs = torch.from_numpy(x)\n",
        "    targets = torch.from_numpy(y) # Ensure targets is a tensor here\n",
        "    if model.use_gpu:\n",
        "      inputs = inputs.cuda()\n",
        "      targets = targets.cuda()\n",
        "\n",
        "    hidden = tuple([state.data for state in hidden])\n",
        "    model.zero_grad()\n",
        "    lstm_output, hidden = model.forward(inputs, hidden)\n",
        "\n",
        "    # Ensure targets are within the valid range [0, num_char-1]\n",
        "    targets = targets.view(batch_size*seq_len).long() # targets should be a tensor here\n",
        "    targets = torch.clamp(targets, 0, num_char-1)\n",
        "\n",
        "    loss = criterion(lstm_output, targets)\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=5)\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    if tracker % 25 == 0:\n",
        "      val_hidden = model.hidden_state(batch_size)\n",
        "      val_losses = []\n",
        "      model.eval()\n",
        "\n",
        "      for x,y in generate_batches(val_data, batch_size, seq_len):\n",
        "        x = one_hot_encoder(x, num_char)\n",
        "        inputs = torch.from_numpy(x)\n",
        "        targets = torch.from_numpy(y) # Ensure targets is a tensor here\n",
        "        if model.use_gpu:\n",
        "          inputs = inputs.cuda()\n",
        "          targets = targets.cuda()\n",
        "        val_hidden = tuple([state.data for state in val_hidden])\n",
        "        lstm_output, val_hidden = model.forward(inputs, val_hidden)\n",
        "\n",
        "        # Ensure targets are within the valid range [0, num_char-1]\n",
        "        targets = targets.view(batch_size*seq_len).long() # targets should be a tensor here\n",
        "        targets = torch.clamp(targets, 0, num_char-1)\n",
        "\n",
        "        val_loss = criterion(lstm_output, targets)\n",
        "        val_losses.append(val_loss.item())\n",
        "      model.train()\n",
        "      print(f\"Epoch: {i} Step: {tracker} Val Loss: {val_loss.item()}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vt0gmHGTd0r5",
        "outputId": "403ccd01-717e-41ec-9477-48dc195e35a7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 Step: 25 Val Loss: 3.2495577335357666\n",
            "Epoch: 0 Step: 50 Val Loss: 3.2430179119110107\n",
            "Epoch: 0 Step: 75 Val Loss: 3.2458484172821045\n",
            "Epoch: 0 Step: 100 Val Loss: 3.2428364753723145\n",
            "Epoch: 0 Step: 125 Val Loss: 3.171109914779663\n",
            "Epoch: 0 Step: 150 Val Loss: 3.0699353218078613\n",
            "Epoch: 0 Step: 175 Val Loss: 3.0071351528167725\n",
            "Epoch: 0 Step: 200 Val Loss: 2.9083383083343506\n",
            "Epoch: 0 Step: 225 Val Loss: 2.7903800010681152\n",
            "Epoch: 0 Step: 250 Val Loss: 2.7165820598602295\n",
            "Epoch: 0 Step: 275 Val Loss: 2.6364428997039795\n",
            "Epoch: 0 Step: 300 Val Loss: 2.517833709716797\n",
            "Epoch: 0 Step: 325 Val Loss: 2.435997486114502\n",
            "Epoch: 0 Step: 350 Val Loss: 2.353422164916992\n",
            "Epoch: 0 Step: 375 Val Loss: 2.2889034748077393\n",
            "Epoch: 0 Step: 400 Val Loss: 2.2449541091918945\n",
            "Epoch: 0 Step: 425 Val Loss: 2.1950573921203613\n",
            "Epoch: 0 Step: 450 Val Loss: 2.1715080738067627\n",
            "Epoch: 0 Step: 475 Val Loss: 2.126555919647217\n",
            "Epoch: 1 Step: 500 Val Loss: 2.0862832069396973\n",
            "Epoch: 1 Step: 525 Val Loss: 2.056349992752075\n",
            "Epoch: 1 Step: 550 Val Loss: 2.034351348876953\n",
            "Epoch: 1 Step: 575 Val Loss: 2.0081043243408203\n",
            "Epoch: 1 Step: 600 Val Loss: 1.985819935798645\n",
            "Epoch: 1 Step: 625 Val Loss: 1.9655494689941406\n",
            "Epoch: 1 Step: 650 Val Loss: 1.9432590007781982\n",
            "Epoch: 1 Step: 675 Val Loss: 1.9234238862991333\n",
            "Epoch: 1 Step: 700 Val Loss: 1.9049423933029175\n",
            "Epoch: 1 Step: 725 Val Loss: 1.8867816925048828\n",
            "Epoch: 1 Step: 750 Val Loss: 1.8662898540496826\n",
            "Epoch: 1 Step: 775 Val Loss: 1.8482433557510376\n",
            "Epoch: 1 Step: 800 Val Loss: 1.831788420677185\n",
            "Epoch: 1 Step: 825 Val Loss: 1.814353346824646\n",
            "Epoch: 1 Step: 850 Val Loss: 1.8018685579299927\n",
            "Epoch: 1 Step: 875 Val Loss: 1.7903746366500854\n",
            "Epoch: 1 Step: 900 Val Loss: 1.7808589935302734\n",
            "Epoch: 1 Step: 925 Val Loss: 1.7623316049575806\n",
            "Epoch: 1 Step: 950 Val Loss: 1.7618027925491333\n",
            "Epoch: 1 Step: 975 Val Loss: 1.7369117736816406\n",
            "Epoch: 2 Step: 1000 Val Loss: 1.7215077877044678\n",
            "Epoch: 2 Step: 1025 Val Loss: 1.7190295457839966\n",
            "Epoch: 2 Step: 1050 Val Loss: 1.7055376768112183\n",
            "Epoch: 2 Step: 1075 Val Loss: 1.7019779682159424\n",
            "Epoch: 2 Step: 1100 Val Loss: 1.689401388168335\n",
            "Epoch: 2 Step: 1125 Val Loss: 1.6825484037399292\n",
            "Epoch: 2 Step: 1150 Val Loss: 1.6740643978118896\n",
            "Epoch: 2 Step: 1175 Val Loss: 1.6680015325546265\n",
            "Epoch: 2 Step: 1200 Val Loss: 1.6567068099975586\n",
            "Epoch: 2 Step: 1225 Val Loss: 1.6464883089065552\n",
            "Epoch: 2 Step: 1250 Val Loss: 1.6397753953933716\n",
            "Epoch: 2 Step: 1275 Val Loss: 1.6358482837677002\n",
            "Epoch: 2 Step: 1300 Val Loss: 1.6204370260238647\n",
            "Epoch: 2 Step: 1325 Val Loss: 1.6210869550704956\n",
            "Epoch: 2 Step: 1350 Val Loss: 1.6160246133804321\n",
            "Epoch: 2 Step: 1375 Val Loss: 1.6072087287902832\n",
            "Epoch: 2 Step: 1400 Val Loss: 1.6043788194656372\n",
            "Epoch: 2 Step: 1425 Val Loss: 1.5972505807876587\n",
            "Epoch: 2 Step: 1450 Val Loss: 1.5867104530334473\n",
            "Epoch: 3 Step: 1475 Val Loss: 1.5744152069091797\n",
            "Epoch: 3 Step: 1500 Val Loss: 1.5682240724563599\n",
            "Epoch: 3 Step: 1525 Val Loss: 1.5673848390579224\n",
            "Epoch: 3 Step: 1550 Val Loss: 1.566955804824829\n",
            "Epoch: 3 Step: 1575 Val Loss: 1.562948226928711\n",
            "Epoch: 3 Step: 1600 Val Loss: 1.5593568086624146\n",
            "Epoch: 3 Step: 1625 Val Loss: 1.5476974248886108\n",
            "Epoch: 3 Step: 1650 Val Loss: 1.546141266822815\n",
            "Epoch: 3 Step: 1675 Val Loss: 1.5478636026382446\n",
            "Epoch: 3 Step: 1700 Val Loss: 1.5438894033432007\n",
            "Epoch: 3 Step: 1725 Val Loss: 1.533705711364746\n",
            "Epoch: 3 Step: 1750 Val Loss: 1.5343927145004272\n",
            "Epoch: 3 Step: 1775 Val Loss: 1.5251888036727905\n",
            "Epoch: 3 Step: 1800 Val Loss: 1.5223028659820557\n",
            "Epoch: 3 Step: 1825 Val Loss: 1.518820881843567\n",
            "Epoch: 3 Step: 1850 Val Loss: 1.5177778005599976\n",
            "Epoch: 3 Step: 1875 Val Loss: 1.5224940776824951\n",
            "Epoch: 3 Step: 1900 Val Loss: 1.5113513469696045\n",
            "Epoch: 3 Step: 1925 Val Loss: 1.5078932046890259\n",
            "Epoch: 3 Step: 1950 Val Loss: 1.5008788108825684\n",
            "Epoch: 4 Step: 1975 Val Loss: 1.4900517463684082\n",
            "Epoch: 4 Step: 2000 Val Loss: 1.4984575510025024\n",
            "Epoch: 4 Step: 2025 Val Loss: 1.4919981956481934\n",
            "Epoch: 4 Step: 2050 Val Loss: 1.4876470565795898\n",
            "Epoch: 4 Step: 2075 Val Loss: 1.4898009300231934\n",
            "Epoch: 4 Step: 2100 Val Loss: 1.4845627546310425\n",
            "Epoch: 4 Step: 2125 Val Loss: 1.4817225933074951\n",
            "Epoch: 4 Step: 2150 Val Loss: 1.479187250137329\n",
            "Epoch: 4 Step: 2175 Val Loss: 1.4761593341827393\n",
            "Epoch: 4 Step: 2200 Val Loss: 1.476775050163269\n",
            "Epoch: 4 Step: 2225 Val Loss: 1.475393295288086\n",
            "Epoch: 4 Step: 2250 Val Loss: 1.4767234325408936\n",
            "Epoch: 4 Step: 2275 Val Loss: 1.4650644063949585\n",
            "Epoch: 4 Step: 2300 Val Loss: 1.4654889106750488\n",
            "Epoch: 4 Step: 2325 Val Loss: 1.4679615497589111\n",
            "Epoch: 4 Step: 2350 Val Loss: 1.4660701751708984\n",
            "Epoch: 4 Step: 2375 Val Loss: 1.4699385166168213\n",
            "Epoch: 4 Step: 2400 Val Loss: 1.461484432220459\n",
            "Epoch: 4 Step: 2425 Val Loss: 1.4575506448745728\n",
            "Epoch: 4 Step: 2450 Val Loss: 1.4515668153762817\n",
            "Epoch: 5 Step: 2475 Val Loss: 1.4473201036453247\n",
            "Epoch: 5 Step: 2500 Val Loss: 1.451187014579773\n",
            "Epoch: 5 Step: 2525 Val Loss: 1.4528189897537231\n",
            "Epoch: 5 Step: 2550 Val Loss: 1.4481021165847778\n",
            "Epoch: 5 Step: 2575 Val Loss: 1.444748044013977\n",
            "Epoch: 5 Step: 2600 Val Loss: 1.444966197013855\n",
            "Epoch: 5 Step: 2625 Val Loss: 1.4415231943130493\n",
            "Epoch: 5 Step: 2650 Val Loss: 1.4412434101104736\n",
            "Epoch: 5 Step: 2675 Val Loss: 1.434755802154541\n",
            "Epoch: 5 Step: 2700 Val Loss: 1.434374451637268\n",
            "Epoch: 5 Step: 2725 Val Loss: 1.4465880393981934\n",
            "Epoch: 5 Step: 2750 Val Loss: 1.4390469789505005\n",
            "Epoch: 5 Step: 2775 Val Loss: 1.4294317960739136\n",
            "Epoch: 5 Step: 2800 Val Loss: 1.4344524145126343\n",
            "Epoch: 5 Step: 2825 Val Loss: 1.4341765642166138\n",
            "Epoch: 5 Step: 2850 Val Loss: 1.4263502359390259\n",
            "Epoch: 5 Step: 2875 Val Loss: 1.4313853979110718\n",
            "Epoch: 5 Step: 2900 Val Loss: 1.4301316738128662\n",
            "Epoch: 5 Step: 2925 Val Loss: 1.4285857677459717\n",
            "Epoch: 6 Step: 2950 Val Loss: 1.4144903421401978\n",
            "Epoch: 6 Step: 2975 Val Loss: 1.4153871536254883\n",
            "Epoch: 6 Step: 3000 Val Loss: 1.4193843603134155\n",
            "Epoch: 6 Step: 3025 Val Loss: 1.4169772863388062\n",
            "Epoch: 6 Step: 3050 Val Loss: 1.4165047407150269\n",
            "Epoch: 6 Step: 3075 Val Loss: 1.4128624200820923\n",
            "Epoch: 6 Step: 3100 Val Loss: 1.4160871505737305\n",
            "Epoch: 6 Step: 3125 Val Loss: 1.4088258743286133\n",
            "Epoch: 6 Step: 3150 Val Loss: 1.415045976638794\n",
            "Epoch: 6 Step: 3175 Val Loss: 1.4187090396881104\n",
            "Epoch: 6 Step: 3200 Val Loss: 1.4098577499389648\n",
            "Epoch: 6 Step: 3225 Val Loss: 1.4120475053787231\n",
            "Epoch: 6 Step: 3250 Val Loss: 1.4073985815048218\n",
            "Epoch: 6 Step: 3275 Val Loss: 1.4050453901290894\n",
            "Epoch: 6 Step: 3300 Val Loss: 1.4125597476959229\n",
            "Epoch: 6 Step: 3325 Val Loss: 1.4183481931686401\n",
            "Epoch: 6 Step: 3350 Val Loss: 1.4144678115844727\n",
            "Epoch: 6 Step: 3375 Val Loss: 1.4048529863357544\n",
            "Epoch: 6 Step: 3400 Val Loss: 1.4145032167434692\n",
            "Epoch: 6 Step: 3425 Val Loss: 1.408015489578247\n",
            "Epoch: 7 Step: 3450 Val Loss: 1.3920674324035645\n",
            "Epoch: 7 Step: 3475 Val Loss: 1.3961445093154907\n",
            "Epoch: 7 Step: 3500 Val Loss: 1.404358148574829\n",
            "Epoch: 7 Step: 3525 Val Loss: 1.3977516889572144\n",
            "Epoch: 7 Step: 3550 Val Loss: 1.3994553089141846\n",
            "Epoch: 7 Step: 3575 Val Loss: 1.397275686264038\n",
            "Epoch: 7 Step: 3600 Val Loss: 1.3977007865905762\n",
            "Epoch: 7 Step: 3625 Val Loss: 1.3924968242645264\n",
            "Epoch: 7 Step: 3650 Val Loss: 1.3968569040298462\n",
            "Epoch: 7 Step: 3675 Val Loss: 1.3992561101913452\n",
            "Epoch: 7 Step: 3700 Val Loss: 1.3978010416030884\n",
            "Epoch: 7 Step: 3725 Val Loss: 1.3928478956222534\n",
            "Epoch: 7 Step: 3750 Val Loss: 1.3873493671417236\n",
            "Epoch: 7 Step: 3775 Val Loss: 1.3926074504852295\n",
            "Epoch: 7 Step: 3800 Val Loss: 1.398313045501709\n",
            "Epoch: 7 Step: 3825 Val Loss: 1.4023492336273193\n",
            "Epoch: 7 Step: 3850 Val Loss: 1.397478461265564\n",
            "Epoch: 7 Step: 3875 Val Loss: 1.3902759552001953\n",
            "Epoch: 7 Step: 3900 Val Loss: 1.3926618099212646\n",
            "Epoch: 8 Step: 3925 Val Loss: 1.3893678188323975\n",
            "Epoch: 8 Step: 3950 Val Loss: 1.3824678659439087\n",
            "Epoch: 8 Step: 3975 Val Loss: 1.3847856521606445\n",
            "Epoch: 8 Step: 4000 Val Loss: 1.386924147605896\n",
            "Epoch: 8 Step: 4025 Val Loss: 1.3899558782577515\n",
            "Epoch: 8 Step: 4050 Val Loss: 1.3839646577835083\n",
            "Epoch: 8 Step: 4075 Val Loss: 1.3858708143234253\n",
            "Epoch: 8 Step: 4100 Val Loss: 1.3890715837478638\n",
            "Epoch: 8 Step: 4125 Val Loss: 1.3874813318252563\n",
            "Epoch: 8 Step: 4150 Val Loss: 1.3872610330581665\n",
            "Epoch: 8 Step: 4175 Val Loss: 1.3899372816085815\n",
            "Epoch: 8 Step: 4200 Val Loss: 1.389299988746643\n",
            "Epoch: 8 Step: 4225 Val Loss: 1.3809287548065186\n",
            "Epoch: 8 Step: 4250 Val Loss: 1.3782891035079956\n",
            "Epoch: 8 Step: 4275 Val Loss: 1.387096881866455\n",
            "Epoch: 8 Step: 4300 Val Loss: 1.3883769512176514\n",
            "Epoch: 8 Step: 4325 Val Loss: 1.3896875381469727\n",
            "Epoch: 8 Step: 4350 Val Loss: 1.3834744691848755\n",
            "Epoch: 8 Step: 4375 Val Loss: 1.3900953531265259\n",
            "Epoch: 8 Step: 4400 Val Loss: 1.3854044675827026\n",
            "Epoch: 9 Step: 4425 Val Loss: 1.3736552000045776\n",
            "Epoch: 9 Step: 4450 Val Loss: 1.3756022453308105\n",
            "Epoch: 9 Step: 4475 Val Loss: 1.3766562938690186\n",
            "Epoch: 9 Step: 4500 Val Loss: 1.3803377151489258\n",
            "Epoch: 9 Step: 4525 Val Loss: 1.3797472715377808\n",
            "Epoch: 9 Step: 4550 Val Loss: 1.3734700679779053\n",
            "Epoch: 9 Step: 4575 Val Loss: 1.3771312236785889\n",
            "Epoch: 9 Step: 4600 Val Loss: 1.3740285634994507\n",
            "Epoch: 9 Step: 4625 Val Loss: 1.374961256980896\n",
            "Epoch: 9 Step: 4650 Val Loss: 1.374566674232483\n",
            "Epoch: 9 Step: 4675 Val Loss: 1.3746014833450317\n",
            "Epoch: 9 Step: 4700 Val Loss: 1.3752951622009277\n",
            "Epoch: 9 Step: 4725 Val Loss: 1.3650755882263184\n",
            "Epoch: 9 Step: 4750 Val Loss: 1.366391658782959\n",
            "Epoch: 9 Step: 4775 Val Loss: 1.3739690780639648\n",
            "Epoch: 9 Step: 4800 Val Loss: 1.3766239881515503\n",
            "Epoch: 9 Step: 4825 Val Loss: 1.3799939155578613\n",
            "Epoch: 9 Step: 4850 Val Loss: 1.3757506608963013\n",
            "Epoch: 9 Step: 4875 Val Loss: 1.37666916847229\n",
            "Epoch: 9 Step: 4900 Val Loss: 1.3723009824752808\n",
            "Epoch: 10 Step: 4925 Val Loss: 1.3680799007415771\n",
            "Epoch: 10 Step: 4950 Val Loss: 1.3672175407409668\n",
            "Epoch: 10 Step: 4975 Val Loss: 1.3666236400604248\n",
            "Epoch: 10 Step: 5000 Val Loss: 1.371857762336731\n",
            "Epoch: 10 Step: 5025 Val Loss: 1.364769458770752\n",
            "Epoch: 10 Step: 5050 Val Loss: 1.3633852005004883\n",
            "Epoch: 10 Step: 5075 Val Loss: 1.3668571710586548\n",
            "Epoch: 10 Step: 5100 Val Loss: 1.3705825805664062\n",
            "Epoch: 10 Step: 5125 Val Loss: 1.361384391784668\n",
            "Epoch: 10 Step: 5150 Val Loss: 1.3656846284866333\n",
            "Epoch: 10 Step: 5175 Val Loss: 1.3704116344451904\n",
            "Epoch: 10 Step: 5200 Val Loss: 1.3643627166748047\n",
            "Epoch: 10 Step: 5225 Val Loss: 1.3595435619354248\n",
            "Epoch: 10 Step: 5250 Val Loss: 1.3604248762130737\n",
            "Epoch: 10 Step: 5275 Val Loss: 1.360927700996399\n",
            "Epoch: 10 Step: 5300 Val Loss: 1.3687580823898315\n",
            "Epoch: 10 Step: 5325 Val Loss: 1.3748975992202759\n",
            "Epoch: 10 Step: 5350 Val Loss: 1.3693569898605347\n",
            "Epoch: 10 Step: 5375 Val Loss: 1.3704043626785278\n",
            "Epoch: 11 Step: 5400 Val Loss: 1.3569620847702026\n",
            "Epoch: 11 Step: 5425 Val Loss: 1.355488896369934\n",
            "Epoch: 11 Step: 5450 Val Loss: 1.3598934412002563\n",
            "Epoch: 11 Step: 5475 Val Loss: 1.3609923124313354\n",
            "Epoch: 11 Step: 5500 Val Loss: 1.3658523559570312\n",
            "Epoch: 11 Step: 5525 Val Loss: 1.3617000579833984\n",
            "Epoch: 11 Step: 5550 Val Loss: 1.358154535293579\n",
            "Epoch: 11 Step: 5575 Val Loss: 1.3590874671936035\n",
            "Epoch: 11 Step: 5600 Val Loss: 1.361905813217163\n",
            "Epoch: 11 Step: 5625 Val Loss: 1.3618662357330322\n",
            "Epoch: 11 Step: 5650 Val Loss: 1.359119176864624\n",
            "Epoch: 11 Step: 5675 Val Loss: 1.3611658811569214\n",
            "Epoch: 11 Step: 5700 Val Loss: 1.3559664487838745\n",
            "Epoch: 11 Step: 5725 Val Loss: 1.356064796447754\n",
            "Epoch: 11 Step: 5750 Val Loss: 1.360425353050232\n",
            "Epoch: 11 Step: 5775 Val Loss: 1.3627389669418335\n",
            "Epoch: 11 Step: 5800 Val Loss: 1.3690037727355957\n",
            "Epoch: 11 Step: 5825 Val Loss: 1.368534803390503\n",
            "Epoch: 11 Step: 5850 Val Loss: 1.3727527856826782\n",
            "Epoch: 11 Step: 5875 Val Loss: 1.364753246307373\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name= 'hidden512_layers3_shakes.net'"
      ],
      "metadata": {
        "id": "dL_DFerRYf5W"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model_dict, model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "bY8tVe30aMna",
        "outputId": "06e4746a-5e1e-42e4-acdf-6fdf58df4b5c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model_dict' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-2e30996bd19b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model_dict' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_char(model, char, hidden=None, k=1):\n",
        "  encoded_text = encoder[char]\n",
        "  encoded_text = np.array([[encoded_text]])\n",
        "  encoded_text = one_hot_encoder(encoded_text, len(model, all_characters))\n",
        "  inputs = torch.from_numpy(encoded_text)\n",
        "  if model.use_gpu:\n",
        "    inputs = inputs.cuda()\n",
        "\n",
        "  hidden = tuple([state.data for state in hidden])\n",
        "  lstm_out, hidden = model(inputs, hidden)\n",
        "  probs = F.softmax(lstm_out, dim=1).data\n",
        "  if model.use_gpu:\n",
        "    probs = probs.cpu\n",
        "\n",
        "  probs, index_positions = probs.topk(k)\n",
        "  index_positions = index_positions.numpy().squeeze()\n",
        "  probs = probs.numpy().flatten()\n",
        "  probs = probs/probs.sum()\n",
        "  char = np.random.choice(index_positions, p=probs)\n",
        "  return model.decoder[char], hidden\n"
      ],
      "metadata": {
        "id": "gA174nffa2cP"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, size, seed='The', k=1):\n",
        "  if model.use_gpu:\n",
        "    model.cuda()\n",
        "  else:\n",
        "    model.cpu()\n",
        "\n",
        "  model.eval()\n",
        "  output_chars = [c for c in seed]\n",
        "  hidden = model.hidden_state(1)\n",
        "  for char in seed:\n",
        "    char, hidden = predict_next_char(model, char, hidden, k=k)\n",
        "\n",
        "  output_chars.append(char)\n",
        "\n",
        "  for i in range(size):\n",
        "    char, hidden = predict_next_char(model, output_chars[-1], hidden, k=k)\n",
        "    output_chars.append(char)\n",
        "\n",
        "  return ''.join(output_chars)"
      ],
      "metadata": {
        "id": "CrKN7YYiilok"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(model, 1000, seed='The ', k=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "IzQ3qzOWjM0R",
        "outputId": "926324e7-df35-4c34-d1f2-0ca02008d6a5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "len() takes exactly one argument (2 given)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-112e3f8fd56f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'The '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-29-11b9f2fdd8f0>\u001b[0m in \u001b[0;36mgenerate_text\u001b[0;34m(model, size, seed, k)\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mchar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_next_char\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0moutput_chars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-499b6e3a4860>\u001b[0m in \u001b[0;36mpredict_next_char\u001b[0;34m(model, char, hidden, k)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mencoded_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mencoded_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoded_text\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mencoded_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_characters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: len() takes exactly one argument (2 given)"
          ]
        }
      ]
    }
  ]
}